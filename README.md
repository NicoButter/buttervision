# üé® ButterVision - Stable Diffusion WebUI

WebUI ligero y personalizado para Stable Diffusion, similar a Automatic1111 pero optimizado y modular.

## ‚ú® Caracter√≠sticas

- **Interfaz web moderna** con Gradio
- **Text-to-Image**: Genera im√°genes desde prompts de texto
- **Image-to-Image**: Transforma im√°genes existentes
- **Soporte para LoRAs**: Carga din√°micamente m√∫ltiples LoRAs
- **Optimizado para baja VRAM**: Funciona con GPUs de 4GB+
- **M√∫ltiples schedulers**: DPM++, Euler, DDIM, etc.
- **Sistema extensible**: Arquitectura modular para a√±adir plugins

## üìã Requisitos

- Python 3.10 o superior
- GPU NVIDIA con CUDA (recomendado 4GB+ VRAM)
- 10GB+ de espacio en disco

## üöÄ Instalaci√≥n

### 1. Clonar el repositorio

```bash
git clone https://github.com/tuusuario/buttervision.git
cd buttervision
```

### 2. Crear entorno virtual (recomendado)

```bash
python -m venv venv

# Linux/Mac
source venv/bin/activate

# Windows
venv\Scripts\activate
```

### 3. Instalar dependencias

**Para CUDA 11.8:**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
```

**Para CUDA 12.1:**
```bash
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
```

**Para CPU (no recomendado, muy lento):**
```bash
pip install torch torchvision
pip install -r requirements.txt
```

### 4. (Opcional) Instalar xformers

xformers proporciona optimizaciones de memoria significativas:

```bash
pip install xformers
```

## üéÆ Uso

### Inicio b√°sico

```bash
python main.py
```

La interfaz se abrir√° autom√°ticamente en: `http://localhost:7860`

### Opciones de l√≠nea de comandos

#### Configuraci√≥n del servidor

```bash
# Cambiar puerto
python main.py --port 7861

# Crear share link p√∫blico (Gradio)
python main.py --share

# A√±adir autenticaci√≥n
python main.py --auth usuario:contrase√±a

# Cambiar host
python main.py --host 127.0.0.1
```

#### Optimizaciones de VRAM

```bash
# GPU con poca VRAM (< 4GB) - Activa todas las optimizaciones + CPU offload
python main.py --lowvram

# GPU con VRAM media (4-6GB) - Optimizaciones sin CPU offload
python main.py --medvram

# Desactivar todas las optimizaciones (para debugging)
python main.py --no-optimizations
```

#### Configuraci√≥n del modelo

```bash
# Usar un modelo diferente
python main.py --model "stabilityai/stable-diffusion-2-1"

# Desactivar float16 (usa m√°s VRAM)
python main.py --no-fp16

# Desactivar xformers
python main.py --no-xformers
```

#### Combinaciones √∫tiles

```bash
# Para GPU de 4GB (ej: GTX 1650)
python main.py --lowvram --share

# Para GPU de 6GB (ej: RTX 3060)
python main.py --medvram

# Para GPU de 8GB+ (ej: RTX 3070)
python main.py

# Usar modelo SD 2.1 con optimizaciones
python main.py --model "stabilityai/stable-diffusion-2-1" --medvram
```

## üìÅ Estructura del proyecto

```
buttervision/
‚îú‚îÄ‚îÄ main.py                 # Punto de entrada principal
‚îú‚îÄ‚îÄ config.py              # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias Python
‚îú‚îÄ‚îÄ README.md             # Este archivo
‚îú‚îÄ‚îÄ LICENSE               # Licencia del proyecto
‚îÇ
‚îú‚îÄ‚îÄ core/                 # N√∫cleo del sistema
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py       # StableDiffusionManager
‚îÇ   ‚îî‚îÄ‚îÄ lora_manager.py   # Gestor de LoRAs
‚îÇ
‚îú‚îÄ‚îÄ ui/                   # Interfaz de usuario
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ interface.py      # Interfaz Gradio
‚îÇ
‚îú‚îÄ‚îÄ models/               # Modelos y recursos
‚îÇ   ‚îú‚îÄ‚îÄ lora/            # Archivos .safetensors de LoRAs
‚îÇ   ‚îú‚îÄ‚îÄ controlnet/      # Modelos de ControlNet
‚îÇ   ‚îî‚îÄ‚îÄ embeddings/      # Textual inversions
‚îÇ
‚îú‚îÄ‚îÄ extensions/           # Plugins/extensiones personalizadas
‚îú‚îÄ‚îÄ outputs/             # Im√°genes generadas
‚îî‚îÄ‚îÄ cache/               # Cache de modelos de HuggingFace
```

## üé® Uso de la interfaz

### Text-to-Image

1. Escribe tu prompt en el campo de texto
2. (Opcional) A√±ade un negative prompt
3. Ajusta los par√°metros:
   - **Steps**: 20-50 para calidad (m√°s = m√°s lento)
   - **CFG Scale**: 7-9 para seguir el prompt
   - **Width/Height**: 512x512 por defecto
   - **Seed**: -1 para aleatorio
4. (Opcional) Carga LoRAs desde el acorde√≥n
5. Haz clic en "Generate"

### Image-to-Image

1. Carga una imagen inicial
2. Escribe el prompt de transformaci√≥n
3. Ajusta **Strength**: 
   - 0.3-0.5: Cambios sutiles
   - 0.6-0.8: Transformaci√≥n moderada
   - 0.9-1.0: Cambio completo
4. Haz clic en "Transform"

### LoRAs

1. Coloca archivos `.safetensors` de LoRAs en `models/lora/`
2. Haz clic en "üîÑ Refrescar LoRAs"
3. Selecciona hasta 2 LoRAs simult√°neos
4. Ajusta sus pesos (0.0 a 2.0, t√≠pico 0.5-1.0)

## üîß Configuraci√≥n avanzada

### Cambiar modelo base

Edita [config.py](config.py):

```python
@dataclass
class ModelConfig:
    model_id: str = "stabilityai/stable-diffusion-2-1"  # Cambia aqu√≠
    # ... resto de configuraci√≥n
```

Modelos populares:
- `runwayml/stable-diffusion-v1-5` (ligero, r√°pido)
- `stabilityai/stable-diffusion-2-1` (mejor calidad)
- `stabilityai/stable-diffusion-xl-base-1.0` (SDXL, requiere m√°s VRAM)

### A√±adir nuevos schedulers

Los schedulers disponibles est√°n en [config.py](config.py). Puedes a√±adir m√°s editando la funci√≥n `get_available_schedulers()`.

### Extender con plugins

Crea scripts Python en la carpeta `extensions/` para a√±adir funcionalidades personalizadas. (Sistema de plugins en desarrollo)

## üìä Consumo de VRAM estimado

| Configuraci√≥n | VRAM | Velocidad |
|--------------|------|-----------|
| SD 1.5 + lowvram | ~3GB | Lento |
| SD 1.5 + medvram | ~4GB | Moderado |
| SD 1.5 est√°ndar | ~5GB | R√°pido |
| SD 2.1 + medvram | ~5GB | Moderado |
| SD 2.1 est√°ndar | ~6GB | R√°pido |
| SDXL + lowvram | ~6GB | Muy lento |
| SDXL est√°ndar | ~10GB | R√°pido |

## üêõ Soluci√≥n de problemas

### "CUDA out of memory"

```bash
# Prueba con optimizaciones m√°s agresivas
python main.py --lowvram

# O reduce la resoluci√≥n de generaci√≥n
# Usa 384x384 o 448x448 en lugar de 512x512
```

### "xformers not available"

```bash
# Instala xformers (mejora significativa)
pip install xformers

# O desact√≠valo si da problemas
python main.py --no-xformers
```

### El modelo se descarga muy lento

Los modelos se descargan de HuggingFace la primera vez. Para SD 1.5 son ~4GB.

Puedes pre-descargarlos:

```bash
python -c "from diffusers import StableDiffusionPipeline; StableDiffusionPipeline.from_pretrained('runwayml/stable-diffusion-v1-5')"
```

### La generaci√≥n es muy lenta

1. Aseg√∫rate de tener GPU CUDA disponible
2. Verifica que xformers est√© instalado
3. Usa schedulers m√°s r√°pidos: DPM++ (2M, 2M Karras) con menos steps

## üõ£Ô∏è Roadmap

- [ ] ControlNet integration
- [ ] Inpainting/Outpainting completo
- [ ] Batch processing
- [ ] Upscaling (ESRGAN, RealESRGAN)
- [ ] Training de LoRAs
- [ ] API REST con FastAPI
- [ ] Sistema de extensiones completo
- [ ] Soporte para Stable Diffusion XL
- [ ] UI m√°s avanzada con React (opcional)

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver [LICENSE](LICENSE) para m√°s detalles.

## üôè Agradecimientos

- [Stability AI](https://stability.ai/) por Stable Diffusion
- [Hugging Face](https://huggingface.co/) por Diffusers
- [Gradio](https://gradio.app/) por la interfaz web
- [AUTOMATIC1111](https://github.com/AUTOMATIC1111/stable-diffusion-webui) por la inspiraci√≥n

## üìû Soporte

¬øProblemas o preguntas? Abre un issue en GitHub o contacta al desarrollador.

---

**¬°Disfruta generando arte con ButterVision! üé®‚ú®**
Sistema de generacion de imagenes
